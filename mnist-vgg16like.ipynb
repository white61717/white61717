{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.45 \n",
    "# set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_Y), (test_X, test_Y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jason\\Anaconda3\\envs\\tensorFlowGpu\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Jason\\Anaconda3\\envs\\tensorFlowGpu\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "train_Y_onehot = enc.fit_transform(train_Y.reshape(-1,1)).toarray()\n",
    "test_Y_onehot = enc.fit_transform(test_Y.reshape(-1,1)).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reshape(*train_X.shape, 1)\n",
    "test_X = test_X.reshape(*test_X.shape, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000, 10)\n",
      "(10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, train_Y_onehot.shape)\n",
    "print(test_X.shape, test_Y_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten,Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(28,28,1)\n",
    "\n",
    "model = Sequential()\n",
    "# block1\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                activation='relu',\n",
    "                input_shape=input_shape))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# block2\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "# dense\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 21s 350us/step - loss: 0.4754 - acc: 0.9295\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 11s 175us/step - loss: 0.0541 - acc: 0.9835\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.0406 - acc: 0.9871\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.0321 - acc: 0.9897\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0241 - acc: 0.9924\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.0231 - acc: 0.99221s - loss: 0\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0191 - acc: 0.9937\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.0190 - acc: 0.9940\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 11s 192us/step - loss: 0.0181 - acc: 0.9943\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0174 - acc: 0.9944\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0151 - acc: 0.9949\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.0165 - acc: 0.9947\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.0138 - acc: 0.9956\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.0134 - acc: 0.9957\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0125 - acc: 0.99620s - loss: 0.0124 \n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.0122 - acc: 0.9962\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0112 - acc: 0.9966\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0131 - acc: 0.99612s - loss: 0.0137 - acc: 0. - ETA:\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.0118 - acc: 0.9963\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0099 - acc: 0.9969\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.0085 - acc: 0.9975\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.0095 - acc: 0.9972\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0096 - acc: 0.9974\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 11s 175us/step - loss: 0.0107 - acc: 0.9970\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0078 - acc: 0.9976\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0101 - acc: 0.9971\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0072 - acc: 0.9980\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0103 - acc: 0.9971\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0082 - acc: 0.99761s - loss: 0\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0083 - acc: 0.9978\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_X, train_Y_onehot, epochs=30, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 81us/step\n",
      "accuracy=0.9921\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_X, test_Y_onehot, batch_size=128)\n",
    "print('accuracy=%s'%score[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorFlowGpu",
   "language": "python",
   "name": "tensorflowgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
